# RobustVQA
Under construction ... 

A list of papers and resources (data, code, etc) for ROBUST visual question answering. 
The list includes, but not limited to the following areas (framework papers are not included) :
- Debiasing VQA models
- VQA on rare questions/answers
- Commonsense VQA
- Grounded and explainable VQA
- Large-scale VQA pre-training

## Datasets
* VQA-v2
* VQA-CP

## References

2020
* KV, Gouthaman, and Anurag Mittal. **Reducing Language Biases in Visual Question Answering with 
  Visually-Grounded Question Encoder.** ECCV 2020. [[paper](https://arxiv.org/pdf/2007.06198.pdf)]
* Teney, Damien, et al. **On the Value of Out-of-Distribution Testing: An Example of Goodhart's Law.** 
  arXiv 2020. [[paper](https://arxiv.org/pdf/2005.09241.pdf)]
* Kervadec, Corentin, et al. **Roses Are Red, Violets Are Blue... but Should VQA Expect Them To?**
    arXiv 2020. [[paper](https://arxiv.org/pdf/2006.05121.pdf)]
* Niu, Yulei, et al. **Counterfactual VQA: A Cause-Effect Look at Language Bias.** 
  arXiv 2020. [[paper](https://arxiv.org/pdf/2006.04315)]
* Abbasnejad, Ehsan, et al. **Counterfactual vision and language learning.** CVPR 2020.
  [[paper](https://openaccess.thecvf.com/content_CVPR_2020/papers/Abbasnejad_Counterfactual_Vision_and_Language_Learning_CVPR_2020_paper.pdf)]
* Chen, Long, et al. **Counterfactual samples synthesizing for robust visual question answering.** CVPR 2020.
  [[paper](https://openaccess.thecvf.com/content_CVPR_2020/papers/Chen_Counterfactual_Samples_Synthesizing_for_Robust_Visual_Question_Answering_CVPR_2020_paper.pdf)]
  [[code](https://github.com/yanxinzju/CSS-VQA)]
* Teney, Damien, Ehsan Abbasnejad, and Anton van den Hengel. **Unshuffling data for improved generalization.** 
  arXiv 2020. [[paper](https://arxiv.org/pdf/2002.11894.pdf)]
* Teney, Damien, Ehsan Abbasnedjad, and Anton van den Hengel. **Learning what makes a difference from counterfactual examples and gradient supervision.**
  arXiv 2020. [[paper](https://arxiv.org/pdf/2004.09034.pdf)]
* Amizadeh, Saeed, et al. **Neuro-Symbolic Visual Reasoning: Disentangling" Visual" from" Reasoning".**
  ICML 2020. [[paper](https://arxiv.org/pdf/2006.11524.pdf)]

2019
* Cadene, Remi, et al. **Rubi: Reducing unimodal biases for visual question answering.**
  NeurIPS 2019. [[paper](http://papers.nips.cc/paper/8371-rubi-reducing-unimodal-biases-for-visual-question-answering.pdf)]
  [[code](https://github.com/cdancette/rubi.bootstrap.pytorch)]
* Clark, Christopher, Mark Yatskar, and Luke Zettlemoyer. **Don't Take the Easy Way Out: Ensemble Based Methods for Avoiding Known Dataset Biases.**
  EMNLP 2019. [[paper](https://arxiv.org/pdf/1909.03683.pdf)] [[code](https://github.com/chrisc36/debias)]
  
2018
* Ramakrishnan, Sainandan, Aishwarya Agrawal, and Stefan Lee. **Overcoming language priors in visual question answering with adversarial regularization.**
    NeurIPS 2018. [[paper](http://papers.nips.cc/paper/7427-overcoming-language-priors-in-visual-question-answering-with-adversarial-regularization.pdf)]

2017
* Kafle, Kushal, and Christopher Kanan. **An analysis of visual question answering algorithms.** 
  ICCV 2017. [[paper](https://openaccess.thecvf.com/content_ICCV_2017/papers/Kafle_An_Analysis_of_ICCV_2017_paper.pdf)]


